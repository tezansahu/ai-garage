{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Description-Based Resume Aligning Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TechStuff\\ai-garage\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "from crewai import Agent, Task, Crew, LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = LLM(\n",
    "#     model=\"ollama/llama3.2:1b\",\n",
    "#     base_url=\"http://localhost:11434\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = LLM(\n",
    "    model=os.getenv(\"AZURE_MODEL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Aligner Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load agent and task configurations from YAML files\n",
    "with open('resume_optimizer_crew/config/agents.yaml', 'r') as f:\n",
    "    agents_config = yaml.safe_load(f)\n",
    "\n",
    "with open('resume_optimizer_crew/config/tasks.yaml', 'r') as f:\n",
    "    tasks_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeAnalyis(BaseModel):\n",
    "    strengths: list[str]\n",
    "    areas_of_improvement: list[str]\n",
    "    recommendations: list[str]\n",
    "    score: int\n",
    "\n",
    "class JobDescriptionAnalysis(BaseModel):\n",
    "    objectives_and_expectations: list[str]\n",
    "    core_competencies: list[str]\n",
    "    ats_friendly_keywords: list[str]\n",
    "\n",
    "class OptimizedResume(BaseModel):\n",
    "    resume_content: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Tool to Read Markdown-Formatted Resumes\n",
    "\n",
    "The `FileReadTool` from `crewai_tools` throws errors due to invalid character encodings present in most markdown files, so we create a custom tool to read from the markdown files using UTF-8 encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.tools import BaseTool\n",
    "\n",
    "class ResumeMarkdownFileReadTool(BaseTool):\n",
    "    name: str = \"resume_markdown_file_read_tool\"\n",
    "    description: str = \"Reads the contents of a resume stored in a markdown file, using the path provided (in UTF-8 format).\"\n",
    "\n",
    "    def _run(self, resume_file_path: str) -> str:\n",
    "        with open(resume_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "            resume_content = f.read()\n",
    "        \n",
    "        return resume_content\n",
    "    \n",
    "resume_read_tool = ResumeMarkdownFileReadTool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Agents, Tasks & Crews based on YAML Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_analyzer = Agent(\n",
    "    config=agents_config[\"resume_analyzer\"],\n",
    "    tools=[resume_read_tool],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "job_description_analyzer = Agent(\n",
    "    config=agents_config[\"job_description_analyzer\"],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "alignment_specialist = Agent(   \n",
    "    config=agents_config[\"alignment_specialist\"],\n",
    "    tools=[resume_read_tool],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_resume = Task(\n",
    "    config=tasks_config[\"analyze_resume\"],\n",
    "    agent=resume_analyzer,\n",
    "    output_pydantic=ResumeAnalyis\n",
    ")\n",
    "\n",
    "analyze_job_description = Task(\n",
    "    config=tasks_config[\"analyze_job_description\"],\n",
    "    agent=job_description_analyzer,\n",
    "    output_pydantic=JobDescriptionAnalysis\n",
    ")\n",
    "\n",
    "fine_tune_resume = Task(\n",
    "    config=tasks_config[\"fine_tune_resume\"],\n",
    "    agent=alignment_specialist,\n",
    "    output_pydantic=OptimizedResume\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "resume_analysis_crew = Crew(\n",
    "    agents=[resume_analyzer],\n",
    "    tasks=[analyze_resume],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "resume_optimization_crew = Crew(\n",
    "    agents=[job_description_analyzer, alignment_specialist],\n",
    "    tasks=[analyze_job_description, fine_tune_resume],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Crews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_analysis_result = resume_analysis_crew.kickoff(\n",
    "    inputs = {\n",
    "        \"resume_path\": \"sample_resume/JonathanWhitmore_DataScience/resume_original.md\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'strengths': ['Extensive experience in data science and data engineering.',\n",
       "  'Strong educational background with a PhD in Physics.',\n",
       "  'Proficient in multiple programming languages including Python, SQL, and R.',\n",
       "  'Experience with data visualization and statistical modeling.',\n",
       "  'Involvement in various data science projects and consulting roles.',\n",
       "  'Good understanding of both theoretical and practical aspects of data science.',\n",
       "  'Experience in publishing, speaking, and contributing to open source projects.',\n",
       "  'Relevant skills in tools such as Jupyter Notebook, pandas, matplotlib, numpy, scikit-learn, etc.'],\n",
       " 'areas_of_improvement': ['The contact information is cluttered and contains unnecessary placeholders.',\n",
       "  'The structure of the resume could be better organized for readability.',\n",
       "  'Inconsistent use of bullet points and formatting.',\n",
       "  'Lack of clear quantifiable achievements in job descriptions.'],\n",
       " 'recommendations': ['Remove placeholders and unnecessary icons from the contact information.',\n",
       "  'Organize the resume with consistent formatting and bullet points for better readability.',\n",
       "  'Highlight key achievements with quantifiable metrics to demonstrate impact.',\n",
       "  'Consider adding a brief summary at the beginning to provide a snapshot of key competencies and experiences.',\n",
       "  'Ensure consistency in the formatting of job titles, dates, and locations.'],\n",
       " 'score': 78}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_analysis_result.pydantic.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_optimization_result = resume_optimization_crew.kickoff(\n",
    "    inputs = {\n",
    "        \"resume_path\": \"sample_resume/JonathanWhitmore_DataScience/resume_original.md\",\n",
    "        \"job_description\": \"\"\"Day to Day\n",
    "\n",
    "At Indeed, our mission is to Help People Get Jobs. Our products help transform the lives of millions of people by connecting them with meaningful employment through the power of AI.\n",
    "As a Senior Data Scientist, you will play a critical role in advancing this mission by leveraging the latest AI developments to drive innovation.\n",
    "In this role, you will assess data and formulate problem statements and associated opportunity sizes. Your contributions will enhance our platform’s application quality capabilities using AI. You will explore the use of AI models to assess job seekers' qualifications for a job while also supporting initiatives like improving the understanding of candidate communication in key Markets. Additionally, you will be driving innovation by using GenAI techniques to assist with applications while also providing AI-powered candidate evaluations to employers.\n",
    "\n",
    "Your work will also involve building and refining automated model retraining pipelines, ensuring that our models stay responsive and effective in the face of evolving data. By utilizing advanced A/B testing frameworks and collaborating across teams, you will continuously assess and optimize the performance of these models. Your efforts will help build smarter systems that directly contribute to the success of millions of job seekers globally.\n",
    "These are just a few examples of the impactful work you will drive in this role. The opportunities are countless.\n",
    "\n",
    "Responsibilities\n",
    "\n",
    "Develop machine learning models from prototype to production\n",
    "Advocate and establish best practices in AI/ML system design, data pipeline architecture, and large-scale deployment.\n",
    "Collaborate cross-functionally with teams across the company on model inference and product applications\n",
    "Break down larger Machine Learning initiatives into pieces that deliver incremental business value and implement them\n",
    "Deeply understand and optimize large-scale distributed AI systems to improve performance and efficiency.\n",
    "Drive the AI/ML strategy by identifying business opportunities and aligning machine learning initiatives with company goals.\n",
    "Influence and guide cross-functional teams in the application of AI/ML to solve key business challenges.\n",
    "Balance technical and product thinking, and show ownership for team goals and Indeed’s mission to help people get jobs\n",
    "Experiment with Proof of Concept Machine Learning models, scale them to production and run iterative A/B experiments to improve our technology\n",
    "Skills/Competencies\n",
    "\n",
    "We are looking for someone with a deep interest in designing and building AI/ML systems, loves thought-provoking assignments, is eager to learn, and wants to work with a variety of technologies to “help people get jobs”.\n",
    "\n",
    "Bachelors in Computer Science, Mathematics, Statistics, or related fields\n",
    "3+ years of industry experience as a Software Engineer, Data Scientist, or Machine Learning Engineer\n",
    "Proven track record of successfully delivering high-impact AI solutions, with a focus on production deployment and operationalization (MLOps).\n",
    "Proven interpersonal and collaboration skills, with experience working alongside product managers, engineers, and executive leaders.\n",
    "Solid knowledge of data structures and algorithms\n",
    "Experience examining and running A/B tests, ability to understand and make business tradeoffs\n",
    "Experience or exposure to training, fine-tuning, and evaluating language models\n",
    "Solid expertise in deep learning frameworks (e.g., TensorFlow, PyTorch), language models, reinforcement learning, and generative AI.\n",
    "\"\"\",\n",
    "    \"recommendations\": \"- \" + \"\\n- \".join(resume_analysis_result.pydantic.recommendations)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Jonathan Whitmore, PhD\n",
      "\n",
      "**Data Scientist | AI/ML Expert**\n",
      "\n",
      "## Contact Information\n",
      "\n",
      "- Location: Mountain View, CA\n",
      "- Phone: +1 650-943-3715\n",
      "- Email: JBWhit@gmail.com\n",
      "- Portfolio: [JonathanWhitmore.com](http://JonathanWhitmore.com)\n",
      "- LinkedIn: [JonathanBWhitmore](https://www.linkedin.com/in/JonathanBWhitmore)\n",
      "- GitHub: [JBWhit](https://github.com/JBWhit)\n",
      "\n",
      "## Summary\n",
      "\n",
      "PhD-educated Data Scientist with extensive experience in AI and Machine Learning, focusing on developing, deploying, and optimizing large-scale distributed AI systems. Proven ability to identify business opportunities and create value through data science and AI/ML innovation. Strong background in data engineering, statistical modeling, and cross-functional collaboration. Passionate about driving AI advancements to enhance product quality and operational efficiency.\n",
      "\n",
      "## Professional Experience\n",
      "\n",
      "### Data Scientist\n",
      "**Silicon Valley Data Science**, Mountain View, CA | 2014 - Present\n",
      "\n",
      "- Led consulting projects for multiple clients, forming cohesive small data science and engineering teams to deliver actionable insights.\n",
      "- Developed and deployed machine learning models, including an ordinal logistic regression model in R, for client-specific use cases.\n",
      "- Created comprehensive data visualizations and statistical analysis reports to support decision-making by senior management.\n",
      "- Analyzed and visualized user behavior migration patterns, contributing to user retention strategy development.\n",
      "- Tools & Technologies: Python, R, SQL, Hive, Impala, Jupyter Notebook, scikit-learn, TensorFlow, PyTorch, pandas, matplotlib, numpy.\n",
      "\n",
      "### Insight Fellow\n",
      "**Insight Data Science**, Palo Alto, CA | 2014\n",
      "\n",
      "- Developed a predictive model for auction sale prices of Abstract Expressionist art, utilizing machine learning techniques.\n",
      "- Presented project findings to industry professionals, showcasing model efficacy and predictive power.\n",
      "- Tools & Technologies: Python, scikit-learn, pandas, numpy, seaborn.\n",
      "\n",
      "### Postdoctoral Research Associate\n",
      "**Swinburne University**, Melbourne, AUS | 2011 - 2014\n",
      "\n",
      "- Cleaned and homogenized large astronomical datasets collected over multiple years, enhancing data reliability for research purposes.\n",
      "- Established an automated data repository process, facilitating streamlined updates and collaborator access.\n",
      "- Employed advanced statistical methods including Markov-Chain Monte Carlo for model building, hypothesis testing, and sensitivity analysis of spectroscopic data.\n",
      "- Tools & Technologies: Python, SQL, R, LATEX, shell scripts.\n",
      "\n",
      "### Graduate Student Researcher\n",
      "**UCSD**, San Diego, CA | 2005 - 2011\n",
      "\n",
      "- Innovated a technique for high-resolution spectroscopic data analysis, revealing previously undetected systematic errors.\n",
      "- Tools & Technologies: Python, R, MATLAB.\n",
      "\n",
      "## Skills\n",
      "\n",
      "- **Programming Languages:** Python, SQL, R, LATEX, Shell Scripting, CSS, HTML\n",
      "- **Machine Learning:** TensorFlow, PyTorch, scikit-learn, pandas, numpy, scipy, pymc3\n",
      "- **Tools & Frameworks:** Jupyter Notebook, Git, Pandoc, matplotlib, Hive, Impala\n",
      "- **Data Visualization:** matplotlib, seaborn\n",
      "- **Statistical Analysis:** Ordinal Logistic Regression, Markov-Chain Monte Carlo, Sensitivity Analysis\n",
      "- **AI/ML Techniques:** Automation, A/B Testing, Generative AI, Proof of Concept Models, MLOps\n",
      "\n",
      "## Education\n",
      "\n",
      "- **PhD in Physics**, University of California San Diego, San Diego, CA, USA, 2011\n",
      "- **MS in Physics**, University of California San Diego, San Diego, CA, USA, 2007\n",
      "- **Bachelor of Science - Magna Cum Laude**, Vanderbilt University, Nashville, TN, USA, 2005\n",
      "  - Triple Major: Physics (Honors), Mathematics, Philosophy\n",
      "\n",
      "## Publications & Speaking\n",
      "\n",
      "- 2016: O’Reilly author - *Jupyter Notebook for Data Science Teams* [Screencast], O’Reilly Media.\n",
      "- 2016: Guest Lecturer - Master in Data Science, UC Berkeley (Lecture on Jupyter Notebook).\n",
      "- 2015: Speaker at OSCON (Open Source Convention).\n",
      "- 2014-2015: Technical Reviewer for *Mastering SciPy* by Francisco J. Blanco-Silva, 2015.\n",
      "- 2012-2014: Developer of *RebalanceAssetAllocation*, a financial asset allocation Python module.\n",
      "- 2013-2014: Contributor to *astropy*, Developer of *dipole_error* (Astronomy Python Module).\n",
      "- 2013: Co-star and Narrator of *Hidden Universe*, a 3D IMAX Astronomy film.\n",
      "\n",
      "## Key Competencies\n",
      "\n",
      "- **Developing AI/ML Models** from prototype to production.\n",
      "- **Establishing Best Practices** in AI/ML systems design.\n",
      "- **Cross-Functional Collaboration** in model inference and product applications.\n",
      "- **Incremental Business Value** delivery through ML initiatives.\n",
      "- **Optimizing Large-Scale** distributed AI systems.\n",
      "- **Identifying AI/ML Strategy Opportunities**.\n",
      "- **Balancing Technical and Product Thinking**.\n",
      "- **Ownership and Alignment with Company Goals**.\n",
      "- **Experimenting and Scaling Proof of Concept Models**.\n",
      "- **Iterative A/B Testing** for technology improvements.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resume_optimization_result.pydantic.resume_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Resume to Markdown Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.\\\\sample_resume\\\\ChloeMartinez_SeniorProductManager.pdf', '.\\\\sample_resume\\\\JasmineBell_UXDesigner.pdf', '.\\\\sample_resume\\\\JohnGonalez_PythonDeveloper.docx', '.\\\\sample_resume\\\\JohnSmith_SalesExecutive.pdf', '.\\\\sample_resume\\\\JonathanWhitmore_DataScience.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "resumes = [\n",
    "    os.path.join(\".\", \"sample_resume\", file) for file in os.listdir(os.path.join(\".\", \"sample_resume\"))\n",
    "]\n",
    "\n",
    "print(resumes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with [Docling](https://ds4sd.github.io/docling/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TechStuff\\ai-garage\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TechStuff\\ai-garage\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tezan\\.cache\\huggingface\\hub\\models--ds4sd--docling-models. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Jonathan Whitmore\n",
      "\n",
      "PhD, Data Scientist\n",
      "\n",
      "## Experience\n",
      "\n",
      "2014-\n",
      "\n",
      "Present\n",
      "\n",
      "2014\n",
      "\n",
      "Insight Fellow , Insight Data Science , Palo Alto, CA, USA.\n",
      "\n",
      "2011-2014\n",
      "\n",
      "Postdoctoral Research Associate , Swinburne University , Melbourne, AUS.\n",
      "\n",
      "2005-2011\n",
      "\n",
      "Graduate Student Researcher , UCSD , San Diego, CA, USA.\n",
      "\n",
      "- { Developed a novel technique to extract information from high resolution spectroscopic data that led to uncovering unknown short-range systematic errors.\n",
      "\n",
      "## Programming and Development Skills\n",
      "\n",
      "Languages\n",
      "\n",
      "Python, SQL (Impala/Hive), R, L A T X, shell scripts, CSS, HTML.\n",
      "\n",
      "E\n",
      "\n",
      "Tools\n",
      "\n",
      "Jupyter Notebook, pandas, matplotlib, numpy, scikit-learn, scipy, pymc3, git, pandoc.\n",
      "\n",
      "## Publishing, Speaking, and Side Projects\n",
      "\n",
      "2016 O'Reilly author: Jupyter Notebook for Data Science Teams [screencast], editor O'Reilly Media.\n",
      "\n",
      "2016 UC Berkeley Guest Lecturer: Master in Data Science lecture on Jupyter Notebook.\n",
      "\n",
      "2015 Open Source Speaker: OSCON.\n",
      "\n",
      "2014-2015 Technical reviewer of Mastering SciPy by Francisco J. Blanco-Silva, 2015.\n",
      "\n",
      "2012-2014 Developer of RebalanceAssetAllocation, a Python module that recommends financial asset class allocations.\n",
      "\n",
      "2013-2014\n",
      "\n",
      "Contributor to astropy; creator of dipole\\_error, an astronomy Python module.\n",
      "\n",
      "2013 Co-star and narrator of Hidden Universe, a 3D IMAX astronomy film playing worldwide.\n",
      "\n",
      "2007-2009\n",
      "\n",
      "Graduate Physics Courses Taken: Stochastic Methods, Computational Physics.\n",
      "\n",
      "## Education\n",
      "\n",
      "2011 PhD Physics , University of California San Diego , San Diego, CA, USA. 2007 MS Physics , University of California San Diego , San Diego, CA, USA. 2005 Bachelor of Science-Magna Cum Laude , Vanderbilt University , Nashville, TN, USA.\n",
      "\n",
      "Triple major: Physics (honors); Mathematics; Philosophy.\n",
      "\n",
      "- { Cleaned noisy and inhomogeneous astronomical data taken over four years by different observing groups.\n",
      "- { Curated central data repository of final products; developed an automated process to update data repository; created web interface for collaborator access to the repository.\n",
      "- { Utilized numerous statistical techniques, including sensitivity analysis on non-linear propagation of errors, Markov-Chain Monte Carlo for model building, and hypothesis testing via information criterion.\n",
      "- { Simulated spectroscopic data to expose systematic errors that challenge long-standing results on whether the fundamental physical constants of the universe are constant.\n",
      "- { Created a Data Science project to predict the auction sale price of Abstract Expressionist art.\n",
      "\n",
      "Mountain View, CA +1 650-943-3715\n",
      "\n",
      "B JBWhit@gmail.com\n",
      "\n",
      "˝ JonathanWhitmore.com\n",
      "\n",
      "JBWhit\n",
      "\n",
      "JonathanBWhitmore\n",
      "\n",
      "Data Scientist , Silicon Valley Data Science , Mountain View, CA, USA.\n",
      "\n",
      "- { Consulting as a member of several small data science/data engineering teams at multiple companies.\n",
      "- { Creating output to explain data analysis, data visualization, and statistical modeling results to managers.\n",
      "- { Modeling survey data responses with ordinal logistic regression in R.\n",
      "- { Analyzing and visualizing user behavior migration.\n"
     ]
    }
   ],
   "source": [
    "converter = DocumentConverter()\n",
    "result = converter.convert(resumes[0])\n",
    "\n",
    "print(result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with [MarkItDown](https://github.com/microsoft/markitdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown import MarkItDown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jonathan Whitmore\n",
      "PhD, Data Scientist\n",
      "\n",
      "Experience\n",
      "\n",
      "Mountain View, CA\n",
      "+1 650-943-3715\n",
      "(cid:66) JBWhit@gmail.com\n",
      "(cid:205) JonathanWhitmore.com\n",
      "JBWhit\n",
      "JonathanBWhitmore\n",
      "\n",
      "2014-\n",
      "Present\n",
      "\n",
      "Data Scientist, Silicon Valley Data Science, Mountain View, CA, USA.\n",
      "(cid:123) Consulting as a member of several small data science/data engineering teams at multiple companies.\n",
      "(cid:123) Creating output to explain data analysis, data visualization, and statistical modeling results to managers.\n",
      "(cid:123) Modeling survey data responses with ordinal logistic regression in R.\n",
      "(cid:123) Analyzing and visualizing user behavior migration.\n",
      "\n",
      "2014 Insight Fellow, Insight Data Science, Palo Alto, CA, USA.\n",
      "\n",
      "(cid:123) Created a Data Science project to predict the auction sale price of Abstract Expressionist art.\n",
      "\n",
      "2011–2014 Postdoctoral Research Associate, Swinburne University, Melbourne, AUS.\n",
      "\n",
      "(cid:123) Cleaned noisy and inhomogeneous astronomical data taken over four years by diﬀerent observing groups.\n",
      "(cid:123) Curated central data repository of ﬁnal products; developed an automated process to update data\n",
      "\n",
      "repository; created web interface for collaborator access to the repository.\n",
      "\n",
      "(cid:123) Utilized numerous statistical techniques, including sensitivity analysis on non-linear propagation of\n",
      "errors, Markov-Chain Monte Carlo for model building, and hypothesis testing via information criterion.\n",
      "(cid:123) Simulated spectroscopic data to expose systematic errors that challenge long-standing results on whether\n",
      "\n",
      "the fundamental physical constants of the universe are constant.\n",
      "\n",
      "2005–2011 Graduate Student Researcher, UCSD, San Diego, CA, USA.\n",
      "\n",
      "(cid:123) Developed a novel technique to extract information from high resolution spectroscopic data that led to\n",
      "\n",
      "uncovering unknown short-range systematic errors.\n",
      "\n",
      "Programming and Development Skills\n",
      "\n",
      "Languages Python, SQL (Impala/Hive), R, LATEX, shell scripts, CSS, HTML.\n",
      "\n",
      "Tools Jupyter Notebook, pandas, matplotlib, numpy, scikit-learn, scipy, pymc3, git, pandoc.\n",
      "\n",
      "Publishing, Speaking, and Side Projects\n",
      "\n",
      "2016 O’Reilly author: Jupyter Notebook for Data Science Teams [screencast], editor O’Reilly Media.\n",
      "2016 UC Berkeley Guest Lecturer: Master in Data Science lecture on Jupyter Notebook.\n",
      "2015 Open Source Speaker: OSCON.\n",
      "\n",
      "2014–2015 Technical reviewer of Mastering SciPy by Francisco J. Blanco-Silva, 2015.\n",
      "2012–2014 Developer of RebalanceAssetAllocation, a Python module that recommends ﬁnancial asset class allocations.\n",
      "2013-2014 Contributor to astropy; creator of dipole_error, an astronomy Python module.\n",
      "\n",
      "2013 Co-star and narrator of Hidden Universe, a 3D IMAX astronomy ﬁlm playing worldwide.\n",
      "\n",
      "2007–2009 Graduate Physics Courses Taken: Stochastic Methods, Computational Physics.\n",
      "\n",
      "Education\n",
      "\n",
      "2011 PhD Physics, University of California San Diego, San Diego, CA, USA.\n",
      "2007 MS Physics, University of California San Diego, San Diego, CA, USA.\n",
      "\n",
      "2005 Bachelor of Science–Magna Cum Laude, Vanderbilt University, Nashville, TN, USA.\n",
      "\n",
      "Triple major: Physics (honors); Mathematics; Philosophy.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md = MarkItDown()\n",
    "result = md.convert(resumes[0])\n",
    "print(result.text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "![](data:image/png;base64...)JOHN **GONALEZ**\n",
      "\n",
      "Python Developer\n",
      "\n",
      "**CONTACT**\n",
      "\n",
      "Pittsburgh, PA\n",
      "\n",
      "1. 456-7890 john1652@gmail.com [LinkedIn](http://linkedin.com/in/john-g) [Github](http://github.com/john-gonzalez)\n",
      "\n",
      "**EDUCATION**\n",
      "\n",
      "**M.S.**\n",
      "\n",
      "**Computer Science**\n",
      "\n",
      "University of Chicago\n",
      "\n",
      "Chicago, IL / 2014 - 2016\n",
      "\n",
      "**B.S.**\n",
      "\n",
      "**Computer Science**\n",
      "\n",
      "University of Pittsburgh\n",
      "\n",
      "Pittsburgh, PA / 2010 - 2014\n",
      "\n",
      "**SKILLS**\n",
      "\n",
      "HTML/ CSS\n",
      "\n",
      "SQL (PostgreSQL, Oracle)\n",
      "\n",
      "JavaScript (Angular)\n",
      "\n",
      "Python (Django)\n",
      "\n",
      "REST APIs (GraphQL)\n",
      "\n",
      "AWS (Redshift, S3)\n",
      "\n",
      "Git\n",
      "\n",
      "**CAREER OBJECTIVE**\n",
      "\n",
      "Experienced Python developer with extensive Django experience looking to continue to develop my skill set on the back-end at a company driven to addressing the climate crisis.\n",
      "\n",
      "**WORK EXPERIENCE**\n",
      "\n",
      "Python Developer\n",
      "\n",
      "| DoorDash / September 2018 - current / Chicago IL | |\n",
      "| --- | --- |\n",
      "| · | Worked on building new Angular components for the customer- |\n",
      "|  | facing web app which improved the time on page for the |\n",
      "| · | average user by 2 minutes |\n",
      "| Worked within an agile team and helped prioritize and scope |\n",
      "|  | feature requests to ensure that the biggest impact features were |\n",
      "| · | worked on first |\n",
      "| Built extensive test coverage for all new features which reduced |\n",
      "|  | the number of customer complaints by 7% |\n",
      "\n",
      "Python Developer\n",
      "\n",
      "Knewton / April 2016 - September 2018 / Pittsburgh PA\n",
      "\n",
      "· Worked alongside another developer to implement RESTful APIs in Django that enabled our internal analytics team to increase reporting speed by 24%\n",
      "\n",
      "· Using Selenium built out a unit testing infrastructure for a client web application that reduced the number of bugs reported by the client by 11% month over month\n",
      "\n",
      "**PROJECTS**\n",
      "\n",
      "**Cryptocurrency Price Tracker**\n",
      "\n",
      "Creator\n",
      "\n",
      "* Incorporated API calls to several applications and stored data eﬃciently in in our PostgreSQL backend\n",
      "* Utilized D3.js to allow users to dynamically visualize price movements over time periods of their choosing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = md.convert(resumes[1])\n",
    "print(result.text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHLOE MARTINEZ\n",
      "Senior Product Manager | Digital Advertising | Monetization Expert\n",
      "\n",
      "E\n",
      "\n",
      "\u00001\u0000\u0000234\u0000\u0000555\u00001234\n",
      "\n",
      "\n",
      "\n",
      "help@enhancv.com\n",
      "\n",
      "q\n",
      "\n",
      "linkedin.com\n",
      "\n",
      "\n",
      "\n",
      "Phoenix, Arizona\n",
      "\n",
      "SUMMARY\n",
      "\n",
      "With over 6 years of product management experience in ad tech, I bring a\n",
      "wealth of knowledge in DSP/SSP platforms, predictive targeting, and advanced\n",
      "modeling to drive product strategy and successful launch execution.\n",
      "\n",
      "EXPERIENCE\n",
      "\n",
      "Senior Product Manager, Adtech Solutions\n",
      "Google\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "01/2018 \u0000 12/2022\n",
      "San Francisco, CA, USA\n",
      "Led the development of a new programmatic advertising platform,\n",
      "overseeing the project from conception to launch, achieving a 20% market\n",
      "share within the first year.\n",
      "Managed cross-functional teams to improve auction logic and yield\n",
      "management, resulting in a 15% revenue increase for our top 100 clients.\n",
      "Orchestrated the integration of machine learning algorithms for predictive\n",
      "targeting, improving ad relevance by 25% and user engagement by 30%.\n",
      "Drove the product roadmap and strategy for a scaled product group and\n",
      "accomplished three major product launches that cumulatively contributed\n",
      "to a yearly revenue growth of 18%.\n",
      "Spearheaded user testing initiatives that enhanced the overall ad\n",
      "experience while maintaining player experience, leading to a decrease in ad\n",
      "blocker usage by 10%.\n",
      "Guided the team through agile transformation that optimized delivery cycles\n",
      "by 40%, increasing product development efficiency and team morale.\n",
      "\n",
      "Product Manager, Programmatic Marketplace\n",
      "Adobe\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "San Jose, CA, USA\n",
      "\n",
      "06/2015 \u0000 12/2017\n",
      "Designed and executed the product strategy for a multi-tenant DSP\n",
      "product, involving 50\u0000 engineering and data science contributors.\n",
      "Launched a feature set improving privacy enhancing technologies, thus\n",
      "increasing platform adoption by 35%.\n",
      "Increased customer satisfaction by 20% through targeted feature updates\n",
      "based on extensive client feedback analysis.\n",
      "Reduced operational overheads by 25% by implementing process\n",
      "efficiencies across the multi-disciplinary product team.\n",
      "Directed product marketing initiatives that improved the go-to-market\n",
      "strategy, enhancing product visibility and adoption within target segments.\n",
      "\n",
      "Associate Product Manager, Mobile Advertising\n",
      "Facebook\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "•\n",
      "\n",
      "Menlo Park, CA, USA\n",
      "\n",
      "01/2013 \u0000 05/2015\n",
      "Managed the product development lifecycle for innovative mobile ad\n",
      "formats, reaching 1M\u0000 downloads.\n",
      "Contributed to a 50% increase in mobile ad revenue in my first year through\n",
      "optimizing in-app ad placements.\n",
      "Collaborated with UX/UI teams to refine ad experience, improving click-\n",
      "through rates by 12%.\n",
      "Supported the creation of ad personalization features, enhancing user\n",
      "experience and advertiser ROI.\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "Master of Science in Data Science\n",
      "Massachusetts Institute of Technology \u0000MIT\u0000\n",
      "\n",
      "01/2010 \u0000 01/2012\n",
      "\n",
      "Cambridge, MA, USA\n",
      "\n",
      "Bachelor of Science in Computer Science\n",
      "University of Arizona\n",
      "01/2006 \u0000 01/2010\n",
      "\n",
      "Tucson, AZ, USA\n",
      "\n",
      "www.enhancv.com\n",
      "\n",
      "KEY ACHIEVEMENTS\n",
      "\n",
      "\n",
      "Developed Top-Ranked Ad Platform\n",
      "\n",
      "Oversaw the conception to launch of a\n",
      "cutting-edge ad platform, immediately\n",
      "capturing 20% market share.\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "0\n",
      "\n",
      "Revenue Growth and Client Engagement\n",
      "\n",
      "Implemented auction logic enhancements,\n",
      "increasing revenue by 15% and establishing\n",
      "stronger client relationships.\n",
      "\n",
      "Leadership in Agile Transformation\n",
      "\n",
      "Led agile transformation efforts, leading to a\n",
      "40% improvement in product delivery\n",
      "timelines and team efficiency.\n",
      "\n",
      "Innovator in Ad Personalization\n",
      "\n",
      "Introduced personalization features that\n",
      "significantly improved user engagement\n",
      "metrics and advertiser value.\n",
      "\n",
      "SKILLS\n",
      "\n",
      "Product Management\n",
      "\n",
      "Ad Tech\n",
      "\n",
      "Programmatic Advertising\n",
      "\n",
      "DSP/SSP Platforms\n",
      "\n",
      "Predictive Targeting\n",
      "\n",
      "Yield Management\n",
      "\n",
      "COURSES\n",
      "\n",
      "Certified Product Manager\n",
      "Association of International Product Marketing &\n",
      "Management \u0000AIPMM\u0000 \u0000 mastering product\n",
      "management lifecycle and strategies.\n",
      "\n",
      "Machine Learning Specialization\n",
      "Coursera by Stanford University - deep dive into\n",
      "machine learning algorithms and their application in\n",
      "advertising technology.\n",
      "\n",
      "Powered by\n",
      "\n",
      "\fLANGUAGES\n",
      "\n",
      "English\n",
      "Native\n",
      "\n",
      "Spanish\n",
      "Proficient\n",
      "\n",
      "www.enhancv.com\n",
      "\n",
      "Powered by\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = md.convert(resumes[2])\n",
    "print(result.text_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison b/w Docling & MarkItDown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TechStuff\\ai-garage\\.venv\\Lib\\site-packages\\docling\\pipeline\\standard_pdf_pipeline.py:189: DeprecationWarning: Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\n",
      "  or self.pipeline_options.generate_table_images\n",
      "d:\\TechStuff\\ai-garage\\.venv\\Lib\\site-packages\\docling\\pipeline\\standard_pdf_pipeline.py:189: DeprecationWarning: Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\n",
      "  or self.pipeline_options.generate_table_images\n",
      "d:\\TechStuff\\ai-garage\\.venv\\Lib\\site-packages\\docling\\pipeline\\standard_pdf_pipeline.py:189: DeprecationWarning: Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\n",
      "  or self.pipeline_options.generate_table_images\n",
      "d:\\TechStuff\\ai-garage\\.venv\\Lib\\site-packages\\docling\\pipeline\\standard_pdf_pipeline.py:189: DeprecationWarning: Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\n",
      "  or self.pipeline_options.generate_table_images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Document   Converter  Time Taken (s)\n",
      "0  .\\sample_resume\\ChloeMartinez_SeniorProductMan...     docling        2.014914\n",
      "1         .\\sample_resume\\JasmineBell_UXDesigner.pdf     docling        1.199052\n",
      "2   .\\sample_resume\\JohnGonalez_PythonDeveloper.docx     docling        0.096088\n",
      "3       .\\sample_resume\\JohnSmith_SalesExecutive.pdf     docling        2.273818\n",
      "4   .\\sample_resume\\JonathanWhitmore_DataScience.pdf     docling        1.037285\n",
      "5  .\\sample_resume\\ChloeMartinez_SeniorProductMan...  markitdown        0.256180\n",
      "6         .\\sample_resume\\JasmineBell_UXDesigner.pdf  markitdown        0.157676\n",
      "7   .\\sample_resume\\JohnGonalez_PythonDeveloper.docx  markitdown        0.039202\n",
      "8       .\\sample_resume\\JohnSmith_SalesExecutive.pdf  markitdown        0.130077\n",
      "9   .\\sample_resume\\JonathanWhitmore_DataScience.pdf  markitdown        0.048968\n",
      "\n",
      "\n",
      "\n",
      "            count      mean       std       min       25%       50%       75%       max\n",
      "Converter                                                                              \n",
      "docling       5.0  1.324232  0.863872  0.096088  1.037285  1.199052  2.014914  2.273818\n",
      "markitdown    5.0  0.126421  0.088648  0.039202  0.048968  0.130077  0.157676  0.256180\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',504)\n",
    "pd.set_option('display.width',1000)\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Measure time taken for each conversion using docling\n",
    "for resume in resumes:\n",
    "    start_time = time.time()\n",
    "    docling_result = converter.convert(resume)\n",
    "    docling_time = time.time() - start_time\n",
    "    results.append({\n",
    "        'Document': resume,\n",
    "        'Converter': 'docling',\n",
    "        'Time Taken (s)': docling_time\n",
    "    })\n",
    "\n",
    "# Measure time taken for each conversion using markitdown\n",
    "for resume in resumes:\n",
    "    start_time = time.time()\n",
    "    markitdown_result = md.convert(resume)\n",
    "    markitdown_time = time.time() - start_time\n",
    "    results.append({\n",
    "        'Document': resume,\n",
    "        'Converter': 'markitdown',\n",
    "        'Time Taken (s)': markitdown_time\n",
    "    })\n",
    "\n",
    "# Create a DataFrame to present the results\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "print(df_results)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Derive insights\n",
    "insights = df_results.groupby('Converter')['Time Taken (s)'].describe()\n",
    "print(insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Description-Based Resume Optimization Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown import MarkItDown\n",
    "from crewai.flow.flow import Flow, start, listen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeOptimizationState(BaseModel):\n",
    "    job_description: str = \"\"\n",
    "    resume_path: Path = \"sample_resume/\"\n",
    "    resume_markdown_path: Path = \"sample_resume/\"\n",
    "    resume_analysis_result: ResumeAnalyis = None\n",
    "    resume_optimization_result: OptimizedResume = None\n",
    "\n",
    "\n",
    "class ResumeOptimizationFlow(Flow[ResumeOptimizationState]):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.md_converter = MarkItDown()\n",
    "\n",
    "\n",
    "    @start()\n",
    "    def convert_resume_to_markdown(self):\n",
    "        print(\"Converting resume to markdown\")\n",
    "        if os.path.exists(self.state.resume_path):\n",
    "            result = self.md_converter.convert(self.state.resume_path)\n",
    "\n",
    "            file_name = os.path.splitext(os.path.basename(self.state.resume_path))[0]\n",
    "            \n",
    "            os.makedirs(f\"sample_resume/{file_name}\", exist_ok=True)\n",
    "\n",
    "            self.state.resume_markdown_path = f\"sample_resume/{file_name}/resume_original.md\"\n",
    "\n",
    "            with open(self.state.resume_markdown_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(result.text_content)\n",
    "            print(\"Resume converted to markdown\\n\")\n",
    "        else:\n",
    "            print(\"Resume path does not exist\")\n",
    "    \n",
    "    @listen(convert_resume_to_markdown)\n",
    "    def resume_analysis(self):\n",
    "        print(\"Analyzing resume\")\n",
    "        resume_analysis_result = resume_analysis_crew.kickoff(\n",
    "            inputs = {\n",
    "                \"resume_path\": self.state.resume_markdown_path\n",
    "            }\n",
    "        )\n",
    "        print(\"Resume analysis complete\\n\")\n",
    "        self.state.resume_analysis_result = resume_analysis_result.pydantic\n",
    "\n",
    "    @listen(resume_analysis)\n",
    "    def save_resume_analysis(self):\n",
    "        print(\"Saving resume analysis\")\n",
    "        file_name = os.path.splitext(os.path.basename(self.state.resume_path))[0]\n",
    "        analysis_path = f\"sample_resume/{file_name}/resume_analysis.json\"\n",
    "        with open(analysis_path, \"w\") as f:\n",
    "            json.dump(self.state.resume_analysis_result.model_dump(), f, indent=4)\n",
    "        print(f\"Resume analysis saved at {analysis_path}\\n\")\n",
    "\n",
    "    @listen(resume_analysis)\n",
    "    def optimize_resume(self):\n",
    "        print(\"Optimizing resume\")\n",
    "        resume_optimization_result = resume_optimization_crew.kickoff(\n",
    "            inputs = {\n",
    "                \"resume_path\": self.state.resume_markdown_path,\n",
    "                \"job_description\": self.state.job_description,\n",
    "                \"recommendations\": \"- \" + \"\\n- \".join(self.state.resume_analysis_result.recommendations)\n",
    "            }\n",
    "        )\n",
    "        print(\"Resume optimization complete\\n\")\n",
    "        self.state.resume_optimization_result = resume_optimization_result.pydantic\n",
    "\n",
    "    @listen(optimize_resume)\n",
    "    def save_optimized_resume(self):\n",
    "        print(\"Saving optimized resume\")\n",
    "        file_name = os.path.splitext(os.path.basename(self.state.resume_path))[0]\n",
    "        optimized_resume_path = f\"sample_resume/{file_name}/resume_optimized.md\"\n",
    "        with open(optimized_resume_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(self.state.resume_optimization_result.resume_content)\n",
    "        print(f\"Aligned resume saved at {optimized_resume_path}\\n\")\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as crewai_flow.html\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "flow = ResumeOptimizationFlow()\n",
    "flow.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.state.resume_path = \"sample_resume/JonathanWhitmore_DataScience.pdf\"\n",
    "\n",
    "flow.state.job_description = \"\"\"\n",
    "Job Title : Lead Data Scientist\n",
    "\n",
    "Location : Hyderabad\n",
    "\n",
    "Company : Awone DataScience\n",
    "\n",
    "\n",
    "\n",
    "Role Description:\n",
    "\n",
    "Awone DataScience is seeking an experienced Lead Data Scientist to join our team. This is a full-time on-site opportunity designed for a senior-level professional with expertise in machine learning, AI, and advanced data science techniques. The ideal candidate will be responsible for developing cutting-edge data models, mentoring junior data scientists, and driving the integration of data science solutions into the company’s products. In this role, you will collaborate with cross-functional teams and communicate insights to both technical and non-technical stakeholders, ensuring that data-driven strategies align with the company's objectives.\n",
    "\n",
    "\n",
    "\n",
    "Key Responsibilities:\n",
    "\n",
    "Design and develop custom data models and algorithms tailored to complex data sets.\n",
    "Lead the development and implementation of advanced machine learning models to solve intricate business problems.\n",
    "Communicate data-driven insights, findings, and recommendations clearly to Product Managers and executives.\n",
    "Mentor and guide a team of junior data scientists, fostering growth and expertise in best practices.\n",
    "Collaborate with cross-functional teams to define and execute data-driven strategies and integrate solutions into the company’s products.\n",
    "Continuously evaluate and refine the performance of existing machine learning models and algorithms.\n",
    "Stay abreast of the latest trends and innovations in AI/ML, proposing new solutions to enhance the company’s capabilities.\n",
    "Ensure end-to-end delivery of scalable, optimized, and enterprise-level AI solutions, including model deployment and monitoring.\n",
    "\n",
    "\n",
    "Qualifications:\n",
    "\n",
    "Education: Bachelor’s or Master’s degree in Computer Science, Engineering, or a related technical field.\n",
    "Experience: A minimum of 5-8 years of experience in data science, with at least 2 years in a leadership role, managing teams of junior data scientists.\n",
    "Proven experience in the end-to-end delivery of scalable, optimized, and enterprise-grade AI/ML solutions.\n",
    "Expertise in fine-tuning and prompt engineering of AI/ML models, particularly in the context of Generative AI (GenAI), Large Language Models (LLMs), and Transformer-based architectures (e.g., GPT, BERT).\n",
    "Hands-on experience in Natural Language Processing (NLP) tools such as Word2Vec, TextBlob, NLTK, SpaCy, Gensim, CoreNLP, BERT, GloVe, and related technologies.\n",
    "Strong experience with cloud platforms such as AWS, Azure, or GCP, including model deployment using frameworks like FastAPI or gRPC.\n",
    "Experience with containerization (Docker) and deploying ML models in Kubernetes clusters.\n",
    "Proficiency in both NoSQL and SQL databases.\n",
    "Strong programming skills in Python and familiarity with relevant data science libraries (e.g., NumPy, Pandas, Scikit-learn, TensorFlow, PyTorch).\n",
    "Hands-on experience with big data technologies such as Hadoop, Spark, and Hive.\n",
    "Expertise in statistical methods, experimental design, and hypothesis testing.\n",
    "Familiarity with MLOps practices, including CI/CD pipelines for machine learning.\n",
    "Strong project management skills, with the ability to juggle multiple projects and deadlines.\n",
    "Excellent communication and presentation skills, with the ability to translate complex technical concepts for non-technical stakeholders.\n",
    "Domain knowledge in Online Reputation Management or prior experience in a product-driven organization is a plus.\n",
    "\n",
    "\n",
    "Additional Skills & Qualities:\n",
    "\n",
    "A deep understanding of AI/ML lifecycle, from data collection to model deployment and maintenance.\n",
    "A collaborative mindset, with the ability to work across departments and teams to achieve business objectives.\n",
    "A passion for innovation and continuous improvement, with a commitment to staying up-to-date on the latest industry trends.\n",
    "Strong problem-solving abilities, with an analytical and data-driven approach to decision-making.\n",
    "\n",
    "\n",
    "If you are a highly skilled and motivated data scientist with a passion for cutting-edge technologies and driving impactful business solutions, we encourage you to apply and join our dynamic team at Awone DataScience.\n",
    "\n",
    "\n",
    "\n",
    "To Apply:\n",
    "\n",
    "Please submit your resume along with a cover letter outlining your relevant experience and why you would be a great fit for the role on hr@awone.ai\n",
    "\n",
    "\n",
    "\n",
    "Compensation\n",
    "\n",
    "Estimated Pay Range: Exact compensation and offers of employment are dependent on circumstances of each case and will be determined based on job-related knowledge, skills, experience, licenses or certifications, and location.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting resume to markdown\n",
      "Resume converted to markdown\n",
      "\n",
      "Analyzing resume\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TechStuff\\ai-garage\\.venv\\Lib\\site-packages\\crewai\\tools\\tool_usage.py:162: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  acceptable_args = tool.args_schema.schema()[\"properties\"].keys()  # type: ignore # Item \"None\" of \"type[BaseModel] | None\" has no attribute \"schema\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume analysis complete\n",
      "\n",
      "Saving resume analysis\n",
      "Resume analysis saved at sample_resume/JonathanWhitmore_DataScience/resume_analysis.json\n",
      "\n",
      "Aligning resume\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TechStuff\\ai-garage\\.venv\\Lib\\site-packages\\crewai\\tools\\tool_usage.py:162: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  acceptable_args = tool.args_schema.schema()[\"properties\"].keys()  # type: ignore # Item \"None\" of \"type[BaseModel] | None\" has no attribute \"schema\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume aligned\n",
      "\n",
      "Saving aligned resume\n",
      "Aligned resume saved at sample_resume/JonathanWhitmore_DataScience/resume_aligned.md\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply a patch to allow nested asyncio loops in Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "flow.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_description': \"\\nJob Title : Lead Data Scientist\\n\\nLocation : Hyderabad\\n\\nCompany : Awone DataScience\\n\\n\\n\\nRole Description:\\n\\nAwone DataScience is seeking an experienced Lead Data Scientist to join our team. This is a full-time on-site opportunity designed for a senior-level professional with expertise in machine learning, AI, and advanced data science techniques. The ideal candidate will be responsible for developing cutting-edge data models, mentoring junior data scientists, and driving the integration of data science solutions into the company’s products. In this role, you will collaborate with cross-functional teams and communicate insights to both technical and non-technical stakeholders, ensuring that data-driven strategies align with the company's objectives.\\n\\n\\n\\nKey Responsibilities:\\n\\nDesign and develop custom data models and algorithms tailored to complex data sets.\\nLead the development and implementation of advanced machine learning models to solve intricate business problems.\\nCommunicate data-driven insights, findings, and recommendations clearly to Product Managers and executives.\\nMentor and guide a team of junior data scientists, fostering growth and expertise in best practices.\\nCollaborate with cross-functional teams to define and execute data-driven strategies and integrate solutions into the company’s products.\\nContinuously evaluate and refine the performance of existing machine learning models and algorithms.\\nStay abreast of the latest trends and innovations in AI/ML, proposing new solutions to enhance the company’s capabilities.\\nEnsure end-to-end delivery of scalable, optimized, and enterprise-level AI solutions, including model deployment and monitoring.\\n\\n\\nQualifications:\\n\\nEducation: Bachelor’s or Master’s degree in Computer Science, Engineering, or a related technical field.\\nExperience: A minimum of 5-8 years of experience in data science, with at least 2 years in a leadership role, managing teams of junior data scientists.\\nProven experience in the end-to-end delivery of scalable, optimized, and enterprise-grade AI/ML solutions.\\nExpertise in fine-tuning and prompt engineering of AI/ML models, particularly in the context of Generative AI (GenAI), Large Language Models (LLMs), and Transformer-based architectures (e.g., GPT, BERT).\\nHands-on experience in Natural Language Processing (NLP) tools such as Word2Vec, TextBlob, NLTK, SpaCy, Gensim, CoreNLP, BERT, GloVe, and related technologies.\\nStrong experience with cloud platforms such as AWS, Azure, or GCP, including model deployment using frameworks like FastAPI or gRPC.\\nExperience with containerization (Docker) and deploying ML models in Kubernetes clusters.\\nProficiency in both NoSQL and SQL databases.\\nStrong programming skills in Python and familiarity with relevant data science libraries (e.g., NumPy, Pandas, Scikit-learn, TensorFlow, PyTorch).\\nHands-on experience with big data technologies such as Hadoop, Spark, and Hive.\\nExpertise in statistical methods, experimental design, and hypothesis testing.\\nFamiliarity with MLOps practices, including CI/CD pipelines for machine learning.\\nStrong project management skills, with the ability to juggle multiple projects and deadlines.\\nExcellent communication and presentation skills, with the ability to translate complex technical concepts for non-technical stakeholders.\\nDomain knowledge in Online Reputation Management or prior experience in a product-driven organization is a plus.\\n\\n\\nAdditional Skills & Qualities:\\n\\nA deep understanding of AI/ML lifecycle, from data collection to model deployment and maintenance.\\nA collaborative mindset, with the ability to work across departments and teams to achieve business objectives.\\nA passion for innovation and continuous improvement, with a commitment to staying up-to-date on the latest industry trends.\\nStrong problem-solving abilities, with an analytical and data-driven approach to decision-making.\\n\\n\\nIf you are a highly skilled and motivated data scientist with a passion for cutting-edge technologies and driving impactful business solutions, we encourage you to apply and join our dynamic team at Awone DataScience.\\n\\n\\n\\nTo Apply:\\n\\nPlease submit your resume along with a cover letter outlining your relevant experience and why you would be a great fit for the role on hr@awone.ai\\n\\n\\n\\nCompensation\\n\\nEstimated Pay Range: Exact compensation and offers of employment are dependent on circumstances of each case and will be determined based on job-related knowledge, skills, experience, licenses or certifications, and location.\\n\",\n",
       " 'resume_path': 'sample_resume/JonathanWhitmore_DataScience.pdf',\n",
       " 'resume_markdown_path': 'sample_resume/JonathanWhitmore_DataScience/resume_original.md',\n",
       " 'resume_analysis_result': {'strengths': ['Extensive experience in data science with a solid academic background.',\n",
       "   'Proficiency in various programming languages and tools used in data science, such as Python, R, SQL, Jupyter Notebook, and more.',\n",
       "   'Strong analytical and statistical skills demonstrated through various roles and projects.',\n",
       "   'Experience in both academic and industry settings, showing versatility.',\n",
       "   'Involvement in publishing, speaking, and contributing to open source projects, highlighting leadership and communication skills.',\n",
       "   'Consistent role in teaching and mentoring, further indicating strong communication abilities.',\n",
       "   'Published author and technical reviewer, underscoring expertise and recognition in the field.'],\n",
       "  'areas_of_improvement': ['Contact information formatting and placement could be improved for better clarity.',\n",
       "   'Some sections have inconsistent bullet point styles which may affect readability.',\n",
       "   'Lacks a clear summary or objective at the beginning to quickly convey key qualifications and career goals.',\n",
       "   'The resume leans heavily on technical duties; more emphasis on results and impact would be beneficial.',\n",
       "   'Some redundancy in listing skills and tools - combining them could improve conciseness.',\n",
       "   'Limited mention of soft skills and their applications in various roles.'],\n",
       "  'recommendations': ['Reformat the contact information to be more straightforward and accessible at the top of the resume.',\n",
       "   'Add a brief summary or objective at the beginning to provide a quick overview of qualifications and goals.',\n",
       "   'Ensure consistent bullet point formatting across all sections to enhance readability.',\n",
       "   'Highlight results and impacts of work, such as specific outcomes of data science projects (e.g., improved decision-making, cost reductions).',\n",
       "   'Combine programming languages and tools into a single section to save space and improve clarity.',\n",
       "   'Incorporate examples of soft skills (e.g., teamwork, problem-solving) and how they contributed to the success of past roles.'],\n",
       "  'score': 85},\n",
       " 'resume_alignment_result': {'resume_content': '# Jonathan Whitmore, PhD\\n\\n**Data Scientist**\\n\\n[Mountain View, CA](mailto:JBWhit@gmail.com) \\n+1 650-943-3715 | [JonathanWhitmore.com](https://JonathanWhitmore.com) | [GitHub](https://github.com/JBWhit)\\n\\n## Summary\\n\\nExperienced Data Scientist with a strong background in advanced data science techniques, machine learning, and artificial intelligence. Proven track record in leading data science projects, mentoring junior data scientists, and delivering data-driven strategies. Adept at integrating data science solutions into products and collaborating with cross-functional teams to achieve impactful results.\\n\\n## Professional Experience\\n\\n### Data Scientist\\n**Silicon Valley Data Science**, Mountain View, CA, USA\\n*2014-Present*\\n- Led multiple consulting projects as part of data science and data engineering teams for various companies.\\n- Developed and deployed statistical models, including ordinal logistic regression, to extract insights from survey data.\\n- Analyzed and visualized user behavior data, enhancing decision-making processes.\\n- Presented complex data analyses and visualizations to stakeholders, improving understanding and actionable insights.\\n\\n### Insight Fellow\\n**Insight Data Science**, Palo Alto, CA, USA\\n*2014*\\n- Designed and implemented a machine learning model to predict auction sale prices for Abstract Expressionist art, achieving high accuracy and reliability.\\n\\n### Postdoctoral Research Associate\\n**Swinburne University**, Melbourne, AUS\\n*2011-2014*\\n- Cleaned and curated astronomical data, developing automated processes to maintain data integrity.\\n- Applied advanced statistical techniques, including Markov-Chain Monte Carlo and hypothesis testing, to simulate and analyze spectroscopic data.\\n- Identified and addressed systematic errors, contributing to significant discoveries in astrophysics.\\n\\n### Graduate Student Researcher\\n**UCSD**, San Diego, CA, USA\\n*2005-2011*\\n- Pioneered new methods to analyze high-resolution spectroscopic data, uncovering novel short-range systematic errors.\\n\\n## Skills\\n\\n**Languages:** Python, SQL, R, LATEX, Shell Scripts, HTML, CSS\\n\\n**Tools and Frameworks:** Jupyter Notebook, Pandas, NumPy, Scikit-learn, SciPy, TensorFlow, PyTorch, Git, Pandoc\\n\\n**Cloud Platforms:** AWS, Azure, GCP\\n\\n**Big Data Technologies:** Hadoop, Spark, Hive\\n\\n**DevOps and MLOps:** Docker, Kubernetes, FastAPI, gRPC, CI/CD pipelines\\n\\n## Publications and Presentations\\n\\n- **O’Reilly Author:** Jupyter Notebook for Data Science Teams [Screencast], O’Reilly Media, 2016\\n- **Guest Lecturer:** Master in Data Science lecture on Jupyter Notebook, UC Berkeley, 2016\\n- **Open Source Speaker:** OSCON, 2015\\n- **Technical Reviewer:** Mastering SciPy, 2015\\n- **Developer:** RebalanceAssetAllocation, a Python module for financial asset allocation, 2014-2015\\n- **Contributor:** Astropy, creator of dipole_error (astronomy Python module), 2013-2014\\n- **Narrator:** Hidden Universe, a 3D IMAX astronomy film, 2013\\n\\n## Education\\n\\n**PhD in Physics**, University of California San Diego, CA, USA, 2011\\n**MS in Physics**, University of California San Diego, CA, USA, 2007\\n**BS in Physics (Honors), Mathematics, Philosophy**, Vanderbilt University, TN, USA, 2005 (Magna Cum Laude)'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow.state.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
